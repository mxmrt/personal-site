<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>What Does It Mean for Machines to Learn?</title>
<style>
@import url('https://fonts.googleapis.com/css2?family=Playfair+Display:ital,wght@0,400;0,700;0,900;1,400;1,700&family=Nunito:wght@300;400;600;700&family=Satisfy&display=swap');
*,*::before,*::after{margin:0;padding:0;box-sizing:border-box}
:root{
  --deep:#0a0a1a;--night:#0d1025;--indigo:#1a1a3e;
  --gold:#f6c85f;--gold-soft:#f6c85f44;--warm:#ff9a56;
  --magic:#a78bfa;--magic-soft:#a78bfa33;
  --ice:#67e8f9;--emerald:#34d399;--rose:#fb7185;
  --text:#e8e4f0;--text-soft:#9994b0;--text-dim:#6b6680;
  --blue:#60a5fa;--orange:#fb923c;
}
html{scroll-behavior:smooth}
body{background:var(--deep);color:var(--text);font-family:'Nunito',sans-serif;overflow-x:hidden}
#stars-canvas{position:fixed;top:0;left:0;width:100%;height:100%;z-index:0;pointer-events:none}

/* HERO */
.hero{position:relative;min-height:100vh;display:flex;flex-direction:column;align-items:center;justify-content:center;text-align:center;z-index:1;padding:40px}
.hero::before{content:'';position:absolute;width:800px;height:800px;background:radial-gradient(circle,var(--gold-soft) 0%,transparent 70%);top:50%;left:50%;transform:translate(-50%,-50%);animation:heroGlow 6s ease-in-out infinite}
@keyframes heroGlow{0%,100%{opacity:.3;transform:translate(-50%,-50%) scale(1)}50%{opacity:.6;transform:translate(-50%,-50%) scale(1.15)}}
.hero-eyebrow{font-family:'Satisfy',cursive;font-size:1.3rem;color:var(--gold);opacity:0;animation:driftUp 1s .3s ease forwards;position:relative}
.hero h1{font-family:'Playfair Display',serif;font-size:clamp(2.5rem,6vw,4.5rem);font-weight:900;line-height:1.1;margin:16px 0;position:relative;opacity:0;animation:driftUp 1.2s .6s ease forwards}
.hero h1 .glow-word{background:linear-gradient(135deg,var(--gold),var(--warm),var(--gold));-webkit-background-clip:text;-webkit-text-fill-color:transparent;background-size:200% auto;animation:shimmer 4s linear infinite}
@keyframes shimmer{0%{background-position:0% center}100%{background-position:200% center}}
.hero-author{font-size:.95rem;color:var(--text-dim);margin-top:8px;position:relative;opacity:0;animation:driftUp 1s 1.1s ease forwards}

/* MODE CHOOSER */
.mode-chooser{display:flex;gap:16px;margin-top:40px;position:relative;opacity:0;animation:driftUp 1s 1.4s ease forwards}
.mode-btn{padding:16px 36px;border:1.5px solid rgba(255,255,255,.12);border-radius:999px;background:rgba(255,255,255,.04);color:var(--text);font-family:'Nunito',sans-serif;font-size:.95rem;font-weight:600;cursor:pointer;transition:all .3s;backdrop-filter:blur(8px);display:flex;align-items:center;gap:10px}
.mode-btn:hover{border-color:var(--gold);background:rgba(246,200,95,.08);color:var(--gold);transform:translateY(-2px)}

/* FLOATING TOGGLE */
.float-toggle{position:fixed;top:24px;right:24px;z-index:200;display:flex;background:rgba(10,10,26,.85);backdrop-filter:blur(16px);border:1px solid rgba(255,255,255,.08);border-radius:999px;padding:4px;opacity:0;pointer-events:none;transition:opacity .4s}
.float-toggle.visible{opacity:1;pointer-events:auto}
.float-toggle button{padding:8px 20px;border:none;border-radius:999px;font-family:'Nunito',sans-serif;font-size:.78rem;font-weight:700;cursor:pointer;transition:all .3s;background:transparent;color:var(--text-dim);letter-spacing:.03em}
.float-toggle button.active{background:linear-gradient(135deg,var(--gold),var(--warm));color:#1a0a08;box-shadow:0 2px 16px var(--gold-soft)}
.float-toggle button:not(.active):hover{color:var(--text)}

/* PROGRESS */
.progress-track{position:fixed;left:0;top:0;width:3px;height:100%;z-index:100;background:rgba(255,255,255,.03)}
.progress-fill{width:100%;height:0%;background:linear-gradient(to bottom,var(--gold),var(--warm));transition:height .1s linear}

/* MODE CONTAINERS */
.mode-essay,.mode-illustrations{display:none;position:relative;z-index:1}
.mode-essay.active,.mode-illustrations.active{display:block}

/* ESSAY */
.essay-container{max-width:720px;margin:0 auto;padding:24px 32px 200px}
.essay-container .section-rule{width:50px;height:2px;background:linear-gradient(90deg,var(--gold),transparent);margin:32px 0 28px;border:none}
.essay-container h2{font-family:'Playfair Display',serif;font-size:2.2rem;font-weight:700;line-height:1.25;margin-bottom:28px}
.essay-container h2 em{font-style:italic}
.essay-container p{color:var(--text-soft);font-size:1.1rem;line-height:1.9;margin-bottom:24px}
.essay-container p em{color:var(--text);font-style:italic}

/* TOOLTIPS */
.tt{position:relative;border-bottom:1px dotted var(--gold);cursor:help;color:var(--text);transition:color .2s}
.tt:hover{color:var(--gold)}
.tt .tt-box{position:absolute;bottom:calc(100% + 10px);left:50%;transform:translateX(-50%);width:280px;padding:14px 16px;background:var(--indigo);border:1px solid rgba(246,200,95,.25);border-radius:12px;box-shadow:0 12px 40px rgba(0,0,0,.5);font-size:.85rem;line-height:1.6;color:var(--text-soft);opacity:0;visibility:hidden;transition:opacity .25s,visibility .25s;z-index:200;pointer-events:none}
.tt:hover .tt-box{opacity:1;visibility:visible}
.tt .tt-box::after{content:'';position:absolute;top:100%;left:50%;transform:translateX(-50%);border:6px solid transparent;border-top-color:var(--indigo)}
.tt .tt-term{display:block;font-weight:700;color:var(--gold);font-size:.72rem;text-transform:uppercase;letter-spacing:.08em;margin-bottom:4px}
.tt .tt-eg{display:block;margin-top:6px;font-style:italic;color:var(--text-dim);font-size:.75rem}

/* ILLUSTRATIONS */
.illus-section{min-height:100vh;display:flex;align-items:center;justify-content:center;padding:80px 24px;position:relative}
.illus-section:nth-child(odd){background:radial-gradient(ellipse at 30% 50%,rgba(26,26,62,.4) 0%,transparent 70%)}
.illus-section:nth-child(even){background:radial-gradient(ellipse at 70% 50%,rgba(26,16,8,.3) 0%,transparent 70%)}
.illus-inner{max-width:900px;width:100%;display:flex;gap:56px;align-items:center;opacity:0;transform:translateY(50px);transition:opacity .8s ease,transform .8s ease}
.illus-inner.visible{opacity:1;transform:translateY(0)}
.illus-inner.reverse{flex-direction:row-reverse}
.illus-text{flex:1;min-width:260px}
.illus-text .it-title{font-family:'Playfair Display',serif;font-size:2rem;font-weight:700;margin-bottom:10px;line-height:1.25}
.illus-text .it-desc{color:var(--text-soft);font-size:1rem;line-height:1.75;margin-bottom:16px}
.illus-text .it-desc em{color:var(--text)}
.illus-text .it-tag{display:inline-block;padding:4px 14px;border-radius:999px;font-size:.68rem;font-weight:700;text-transform:uppercase;letter-spacing:.1em}
.tag-purple{background:#6366f122;color:#a5b4fc;border:1px solid #6366f144}
.tag-gold{background:#f6c85f22;color:#f6c85f;border:1px solid #f6c85f44}
.tag-green{background:#10b98122;color:#34d399;border:1px solid #10b98144}
.tag-rose{background:#fb718522;color:#fda4af;border:1px solid #fb718544}
.tag-ice{background:#67e8f922;color:#67e8f9;border:1px solid #67e8f944}
.tag-blue{background:#3b82f622;color:#93c5fd;border:1px solid #3b82f644}
.tag-warm{background:#ff9a5622;color:#ffbb88;border:1px solid #ff9a5644}

/* FINALE */
.illus-finale{min-height:60vh;display:flex;align-items:center;justify-content:center;text-align:center;padding:80px 24px}
.illus-finale .fin-inner{max-width:640px;opacity:0;transform:translateY(40px);transition:opacity 1s,transform 1s}
.illus-finale .fin-inner.visible{opacity:1;transform:translateY(0)}
.illus-finale h2{font-family:'Playfair Display',serif;font-size:2.5rem;font-weight:900;margin-bottom:16px;background:linear-gradient(135deg,var(--gold),var(--warm));-webkit-background-clip:text;-webkit-text-fill-color:transparent}
.illus-finale p{color:var(--text-soft);line-height:1.8;font-size:1.05rem}

@keyframes driftUp{from{opacity:0;transform:translateY(24px)}to{opacity:1;transform:translateY(0)}}
@keyframes fadeLoop{0%,100%{opacity:.3}50%{opacity:1}}

/* ANIM BOX */
.anim{width:380px;height:320px;position:relative;overflow:hidden;border-radius:16px;background:rgba(10,10,26,.6);border:1px solid rgba(255,255,255,.04);flex-shrink:0}

/* 1. SUPERVISED */
.anim-supervised .pair{position:absolute;display:flex;align-items:center;gap:6px;font-size:.7rem;font-weight:700;opacity:0;animation:pairFlow 4s ease-in-out infinite}
.anim-supervised .pair .inp{width:32px;height:32px;border-radius:8px;display:flex;align-items:center;justify-content:center;background:rgba(99,102,241,.2);border:1px solid rgba(99,102,241,.4);font-size:1rem}
.anim-supervised .pair .arrow{color:var(--text-dim)}
.anim-supervised .pair .lbl{padding:3px 7px;border-radius:6px;font-size:.65rem}
.anim-supervised .pair .lbl.pos{background:rgba(52,211,153,.2);color:var(--emerald);border:1px solid rgba(52,211,153,.3)}
.anim-supervised .pair .lbl.neg{background:rgba(251,113,133,.2);color:var(--rose);border:1px solid rgba(251,113,133,.3)}
.anim-supervised .pair:nth-child(1){top:8%;left:6%;animation-delay:0s}
.anim-supervised .pair:nth-child(2){top:25%;left:10%;animation-delay:.6s}
.anim-supervised .pair:nth-child(3){top:42%;left:4%;animation-delay:1.2s}
.anim-supervised .pair:nth-child(4){top:59%;left:8%;animation-delay:1.8s}
.anim-supervised .pair:nth-child(5){top:76%;left:6%;animation-delay:2.4s}
@keyframes pairFlow{0%{opacity:0;transform:translateX(0)}15%{opacity:1}70%{opacity:1;transform:translateX(130px)}85%{opacity:0;transform:translateX(160px)}100%{opacity:0;transform:translateX(0)}}
.anim-supervised .model-box{position:absolute;right:12%;top:50%;transform:translateY(-50%);width:85px;height:110px;border-radius:12px;background:linear-gradient(135deg,rgba(99,102,241,.15),rgba(167,139,250,.1));border:1.5px solid rgba(99,102,241,.3);display:flex;align-items:center;justify-content:center;font-size:.6rem;font-weight:700;color:#a5b4fc;text-transform:uppercase;letter-spacing:.1em}

/* 2. UNSUPERVISED */
.anim-unsupervised .dot{position:absolute;width:10px;height:10px;border-radius:50%;background:#555}
.anim-unsupervised .dot.ca{animation:toA 5s 1.5s ease forwards}
.anim-unsupervised .dot.cb{animation:toB 5s 2s ease forwards}
.anim-unsupervised .dot.cc{animation:toC 5s 2.5s ease forwards}
@keyframes toA{to{background:var(--magic);box-shadow:0 0 8px var(--magic)}}
@keyframes toB{to{background:var(--emerald);box-shadow:0 0 8px var(--emerald)}}
@keyframes toC{to{background:var(--gold);box-shadow:0 0 8px var(--gold)}}

/* 3. SEMI-SUPERVISED */
.anim-semi .dot{position:absolute;width:12px;height:12px;border-radius:50%}
.anim-semi .dot.labeled{box-shadow:0 0 10px currentColor;z-index:2}
.anim-semi .dot.unlabeled{background:#444;border:1px solid #555}
.anim-semi .dot.unlabeled.spread-a{animation:spreadA 4s 2s ease forwards}
.anim-semi .dot.unlabeled.spread-b{animation:spreadB 4s 2.5s ease forwards}
@keyframes spreadA{to{background:var(--magic);border-color:var(--magic);box-shadow:0 0 6px var(--magic)}}
@keyframes spreadB{to{background:var(--emerald);border-color:var(--emerald);box-shadow:0 0 6px var(--emerald)}}
.anim-semi .ripple{position:absolute;border-radius:50%;border:1px solid;opacity:0}
.anim-semi .ripple.ra{border-color:var(--magic);animation:rippleOut 3s 1.5s ease-out forwards}
.anim-semi .ripple.rb{border-color:var(--emerald);animation:rippleOut 3s 2s ease-out forwards}
@keyframes rippleOut{0%{width:20px;height:20px;opacity:.8}100%{width:160px;height:160px;opacity:0}}

/* 4. SELF-SUPERVISED */
.anim-selfsup .sentence-box{width:88%;position:absolute;top:50%;left:50%;transform:translate(-50%,-50%)}
.anim-selfsup .sentence{padding:14px 18px;border-radius:12px;background:rgba(99,102,241,.08);border:1px solid rgba(99,102,241,.2);font-size:.85rem;color:var(--text-soft);line-height:1.8;margin-bottom:12px;opacity:0}
.anim-selfsup .sentence:nth-child(1){animation:sentIn 8s 0s ease infinite}
.anim-selfsup .sentence:nth-child(2){animation:sentIn 8s 4s ease infinite}
.anim-selfsup .mask{display:inline-block;padding:2px 10px;border-radius:6px;background:rgba(246,200,95,.2);border:1px dashed var(--gold);color:var(--gold);font-weight:700;min-width:50px;text-align:center}
.anim-selfsup .reveal{display:inline-block;opacity:0;color:var(--emerald);font-weight:700}
.anim-selfsup .sentence:nth-child(1) .reveal{animation:revealW 8s 1.5s ease infinite}
.anim-selfsup .sentence:nth-child(2) .reveal{animation:revealW 8s 5.5s ease infinite}
@keyframes sentIn{0%{opacity:0;transform:translateY(8px)}8%{opacity:1;transform:translateY(0)}45%{opacity:1}50%{opacity:0}100%{opacity:0}}
@keyframes revealW{0%,18%{opacity:0}25%{opacity:1}45%{opacity:1}50%{opacity:0}100%{opacity:0}}

/* 5. RL */
.anim-rl .grid{position:absolute;top:50%;left:50%;transform:translate(-50%,-50%);display:grid;grid-template-columns:repeat(5,44px);grid-template-rows:repeat(5,44px);gap:3px}
.anim-rl .cell{border-radius:6px;background:rgba(255,255,255,.03);border:1px solid rgba(255,255,255,.05)}
.anim-rl .cell.wall{background:rgba(251,113,133,.1);border-color:rgba(251,113,133,.2)}
.anim-rl .cell.goal{background:rgba(52,211,153,.15);border-color:rgba(52,211,153,.3);display:flex;align-items:center;justify-content:center;font-size:1.2rem}
.anim-rl .agent-dot{position:absolute;width:20px;height:20px;border-radius:50%;background:radial-gradient(circle,var(--rose),#e11d48);box-shadow:0 0 16px var(--rose);animation:agentPath 6s ease-in-out infinite;z-index:5}
@keyframes agentPath{0%{top:83%;left:8%;box-shadow:0 0 14px var(--rose)}10%{top:83%;left:27%}15%{top:83%;left:27%;box-shadow:0 0 24px red}20%{top:83%;left:8%}30%{top:64%;left:8%}45%{top:64%;left:46%}55%{top:45%;left:46%}70%{top:27%;left:46%}80%{top:27%;left:65%}90%{top:8%;left:83%;box-shadow:0 0 30px var(--emerald)}100%{top:83%;left:8%;box-shadow:0 0 14px var(--rose)}}
.anim-rl .rew{position:absolute;font-size:.65rem;font-weight:700;opacity:0;animation:rewFlash 6s ease infinite}
.anim-rl .rew.neg-r{color:var(--rose);top:78%;left:30%;animation-delay:.9s}
.anim-rl .rew.pos-r{color:var(--emerald);top:5%;right:8%;animation-delay:5.4s}
@keyframes rewFlash{0%,14%{opacity:0}15%{opacity:1}25%{opacity:0}100%{opacity:0}}

/* 6. RLHF */
.anim-rlhf .response-pair{position:absolute;top:12%;left:50%;transform:translateX(-50%);display:flex;gap:12px;width:92%}
.anim-rlhf .resp{flex:1;padding:12px;border-radius:10px;font-size:.72rem;line-height:1.5;color:var(--text-soft);background:rgba(255,255,255,.03);border:1.5px solid rgba(255,255,255,.08)}
.anim-rlhf .resp .resp-label{font-weight:700;font-size:.58rem;text-transform:uppercase;letter-spacing:.1em;margin-bottom:5px;color:var(--text-dim)}
.anim-rlhf .resp.chosen{animation:chosenGlow 6s 2s ease infinite}
@keyframes chosenGlow{0%,30%{border-color:rgba(255,255,255,.08);box-shadow:none}40%{border-color:var(--emerald);box-shadow:0 0 20px rgba(52,211,153,.2)}80%{border-color:var(--emerald);box-shadow:0 0 20px rgba(52,211,153,.2)}90%{border-color:rgba(255,255,255,.08);box-shadow:none}100%{border-color:rgba(255,255,255,.08)}}
.anim-rlhf .resp.rejected{animation:rejDim 6s 2s ease infinite}
@keyframes rejDim{0%,30%{opacity:1}40%{opacity:.35}80%{opacity:.35}90%{opacity:1}100%{opacity:1}}
.anim-rlhf .human-icon{position:absolute;bottom:16%;left:50%;transform:translateX(-50%);font-size:1.8rem;opacity:0;animation:judgeApp 6s 1.5s ease infinite}
.anim-rlhf .pick-arrow{position:absolute;bottom:30%;left:25%;font-size:.8rem;color:var(--emerald);font-weight:700;opacity:0;animation:pickShow 6s 2.5s ease infinite}
@keyframes judgeApp{0%{opacity:0}10%{opacity:1}80%{opacity:1}90%{opacity:0}100%{opacity:0}}
@keyframes pickShow{0%,8%{opacity:0}15%{opacity:1}75%{opacity:1}85%{opacity:0}100%{opacity:0}}

/* 7. RLAIF */
.anim-rlaif .response-pair{position:absolute;top:12%;left:50%;transform:translateX(-50%);display:flex;gap:12px;width:92%}
.anim-rlaif .resp{flex:1;padding:12px;border-radius:10px;font-size:.72rem;line-height:1.5;color:var(--text-soft);background:rgba(255,255,255,.03);border:1.5px solid rgba(255,255,255,.08)}
.anim-rlaif .resp .resp-label{font-weight:700;font-size:.58rem;text-transform:uppercase;letter-spacing:.1em;margin-bottom:5px;color:var(--text-dim)}
.anim-rlaif .resp.chosen{animation:chosenGlow 6s 2s ease infinite}
.anim-rlaif .resp.rejected{animation:rejDim 6s 2s ease infinite}
.anim-rlaif .ai-icon{position:absolute;bottom:16%;left:50%;transform:translateX(-50%);font-size:1.8rem;opacity:0;animation:judgeApp 6s 1.5s ease infinite}
.anim-rlaif .pick-arrow{position:absolute;bottom:30%;right:25%;font-size:.8rem;color:var(--emerald);font-weight:700;opacity:0;animation:pickShow 6s 2.5s ease infinite}

/* 8. TRANSFER */
.anim-transfer .task-box{position:absolute;width:110px;height:75px;border-radius:12px;display:flex;align-items:center;justify-content:center;flex-direction:column;font-size:.62rem;font-weight:700;text-transform:uppercase;letter-spacing:.07em}
.anim-transfer .task-a{left:6%;top:50%;transform:translateY(-50%);background:rgba(99,102,241,.15);border:1.5px solid rgba(99,102,241,.3);color:#a5b4fc}
.anim-transfer .task-b{right:6%;top:50%;transform:translateY(-50%);background:rgba(52,211,153,.08);border:1.5px solid rgba(52,211,153,.15);color:#6ee7b7;animation:tbLight 5s 2.5s ease forwards}
@keyframes tbLight{to{background:rgba(52,211,153,.2);border-color:rgba(52,211,153,.4);box-shadow:0 0 30px rgba(52,211,153,.15)}}
.anim-transfer .tf-arrow{position:absolute;top:50%;left:32%;width:24%;height:2px;transform:translateY(-50%)}
.anim-transfer .tf-arrow::before{content:'';position:absolute;width:0;height:100%;background:linear-gradient(90deg,#6366f1,var(--emerald));animation:arrowFl 4s 1s ease forwards}
@keyframes arrowFl{to{width:100%}}
.anim-transfer .tf-arrow::after{content:'â–¸';position:absolute;right:-12px;top:-9px;font-size:1rem;color:var(--emerald);opacity:0;animation:arrowHd 4s 2.5s ease forwards}
@keyframes arrowHd{to{opacity:1}}
.anim-transfer .k-dot{position:absolute;width:8px;height:8px;border-radius:50%;background:var(--magic);top:48%;opacity:0;animation:kMove 4s ease infinite}
.anim-transfer .k-dot:nth-child(4){animation-delay:0s;left:30%}
.anim-transfer .k-dot:nth-child(5){animation-delay:.4s;left:28%}
.anim-transfer .k-dot:nth-child(6){animation-delay:.8s;left:32%}
@keyframes kMove{0%{opacity:0;transform:translateX(0)}20%{opacity:1}80%{opacity:.8;transform:translateX(75px)}100%{opacity:0;transform:translateX(90px)}}

/* 9. META */
.anim-meta .task-cards{position:absolute;top:50%;left:50%;transform:translate(-50%,-50%);width:85%}
.anim-meta .task-card{padding:10px 14px;border-radius:10px;background:rgba(103,232,249,.06);border:1px solid rgba(103,232,249,.15);margin-bottom:7px;display:flex;justify-content:space-between;align-items:center;font-size:.7rem;opacity:0}
.anim-meta .task-card .t-name{color:var(--ice);font-weight:600}
.anim-meta .task-card .t-examples{color:var(--text-dim)}
.anim-meta .task-card .t-speed{font-weight:700;font-size:.62rem;padding:2px 8px;border-radius:6px}
.anim-meta .t-speed.slow{background:rgba(251,113,133,.15);color:var(--rose)}
.anim-meta .t-speed.med{background:rgba(246,200,95,.15);color:var(--gold)}
.anim-meta .t-speed.fast{background:rgba(52,211,153,.15);color:var(--emerald)}
.anim-meta .t-speed.instant{background:rgba(52,211,153,.25);color:#86efac}
.anim-meta .task-card:nth-child(1){animation:tkRv 10s 0s ease infinite}
.anim-meta .task-card:nth-child(2){animation:tkRv 10s 2s ease infinite}
.anim-meta .task-card:nth-child(3){animation:tkRv 10s 3.5s ease infinite}
.anim-meta .task-card:nth-child(4){animation:tkRv 10s 4.5s ease infinite}
.anim-meta .task-card:nth-child(5){animation:tkRv 10s 5.2s ease infinite}
@keyframes tkRv{0%{opacity:0;transform:translateY(6px)}5%{opacity:1;transform:translateY(0)}85%{opacity:1}92%{opacity:0}100%{opacity:0}}

/* 10. CONTINUAL */
.anim-continual .skill-stack{position:absolute;top:50%;left:50%;transform:translate(-50%,-50%);width:75%}
.anim-continual .skill{padding:10px 16px;border-radius:8px;margin-bottom:6px;font-size:.72rem;font-weight:600;display:flex;justify-content:space-between;align-items:center}
.anim-continual .skill .s-bar{width:50px;height:6px;border-radius:3px;background:rgba(255,255,255,.1);overflow:hidden}
.anim-continual .skill .s-fill{height:100%;border-radius:3px}
.anim-continual .skill.s1{background:rgba(99,102,241,.12);color:#a5b4fc;border:1px solid rgba(99,102,241,.2)}
.anim-continual .skill.s2{background:rgba(52,211,153,.12);color:#6ee7b7;border:1px solid rgba(52,211,153,.2)}
.anim-continual .skill.s3{background:rgba(246,200,95,.12);color:var(--gold);border:1px solid rgba(246,200,95,.2);opacity:0;animation:newSkill 8s 2s ease infinite}
.anim-continual .s1 .s-fill{background:#6366f1;animation:barHold 8s ease infinite}
.anim-continual .s2 .s-fill{background:var(--emerald);animation:barHold 8s .3s ease infinite}
.anim-continual .s3 .s-fill{background:var(--gold);animation:barGrow 8s 3s ease infinite}
@keyframes barHold{0%{width:85%}30%{width:85%}50%{width:82%}70%{width:85%}100%{width:85%}}
@keyframes barGrow{0%{width:0}50%{width:75%}100%{width:75%}}
@keyframes newSkill{0%{opacity:0;transform:translateY(10px)}15%{opacity:1;transform:translateY(0)}85%{opacity:1}95%{opacity:0}100%{opacity:0}}
.anim-continual .forget-lbl{position:absolute;bottom:10%;left:50%;transform:translateX(-50%);font-size:.58rem;color:var(--text-dim);text-transform:uppercase;letter-spacing:.1em;opacity:0;animation:fadeLoop 6s 4s ease infinite}

/* 11. ICL */
.anim-icl .progression{position:absolute;top:50%;left:50%;transform:translate(-50%,-50%);width:88%}
.anim-icl .stage{display:flex;align-items:center;gap:10px;margin-bottom:10px;opacity:0;font-size:.75rem}
.anim-icl .stage:nth-child(1){animation:stgIn 8s 0s ease infinite}
.anim-icl .stage:nth-child(2){animation:stgIn 8s 2s ease infinite}
.anim-icl .stage:nth-child(3){animation:stgIn 8s 3.5s ease infinite}
@keyframes stgIn{0%{opacity:0}8%{opacity:1}85%{opacity:1}95%{opacity:0}100%{opacity:0}}
.anim-icl .stage .s-label{flex:0 0 65px;font-weight:700;text-transform:uppercase;font-size:.6rem;letter-spacing:.08em}
.anim-icl .stage .s-bar-track{flex:1;height:18px;border-radius:8px;background:rgba(255,255,255,.05);overflow:hidden}
.anim-icl .stage .s-bar-fill{height:100%;border-radius:8px;display:flex;align-items:center;justify-content:flex-end;padding-right:6px;font-size:.6rem;font-weight:700}
.anim-icl .stage.zero .s-bar-fill{width:20%;background:rgba(251,113,133,.3);color:var(--rose)}
.anim-icl .stage.few .s-bar-fill{width:65%;background:rgba(246,200,95,.3);color:var(--gold)}
.anim-icl .stage.more .s-bar-fill{width:92%;background:rgba(52,211,153,.3);color:var(--emerald)}
.anim-icl .ex-area{margin-top:14px;padding:10px;border-radius:10px;background:rgba(52,211,153,.04);border:1px solid rgba(52,211,153,.1);font-size:.65rem;color:var(--text-dim);line-height:1.6;opacity:0;animation:stgIn 8s 1s ease infinite}
.anim-icl .ex-area .ex{color:#6ee7b7}

/* 12. ONLINE */
.anim-online .conveyor{position:absolute;top:50%;left:0;right:0;transform:translateY(-50%);height:2px;background:rgba(255,255,255,.06)}
.anim-online .dp{position:absolute;width:20px;height:20px;border-radius:50%;top:50%;transform:translateY(-50%);opacity:0;animation:convMove 8s linear infinite}
.anim-online .dp:nth-child(2){background:rgba(99,102,241,.6);border:1.5px solid #6366f1;left:-20px;animation-delay:0s}
.anim-online .dp:nth-child(3){background:rgba(52,211,153,.6);border:1.5px solid var(--emerald);left:-20px;animation-delay:2s}
.anim-online .dp:nth-child(4){background:rgba(246,200,95,.6);border:1.5px solid var(--gold);left:-20px;animation-delay:4s}
.anim-online .dp:nth-child(5){background:rgba(251,113,133,.6);border:1.5px solid var(--rose);left:-20px;animation-delay:6s}
@keyframes convMove{0%{left:-20px;opacity:0}5%{opacity:1}45%{opacity:1;left:48%}50%{opacity:0;left:52%}100%{opacity:0;left:52%}}
.anim-online .gauge{position:absolute;top:50%;left:50%;transform:translate(-50%,-50%);width:56px;height:56px;border-radius:50%;background:rgba(255,255,255,.03);border:2px solid rgba(255,255,255,.1);display:flex;align-items:center;justify-content:center;z-index:3}
.anim-online .needle{width:2px;height:22px;background:var(--gold);transform-origin:bottom center;border-radius:2px;animation:needleTk 8s ease infinite}
@keyframes needleTk{0%{transform:rotate(-40deg)}14%{transform:rotate(-40deg)}16%{transform:rotate(-10deg)}28%{transform:rotate(-10deg)}30%{transform:rotate(15deg)}53%{transform:rotate(15deg)}55%{transform:rotate(35deg)}100%{transform:rotate(35deg)}}
.anim-online .flash{position:absolute;top:50%;left:50%;transform:translate(-50%,-50%);width:66px;height:66px;border-radius:50%;border:2px solid var(--gold);opacity:0;animation:updPulse 8s ease infinite}
@keyframes updPulse{0%,11%{opacity:0;transform:translate(-50%,-50%) scale(1)}13%{opacity:.6;transform:translate(-50%,-50%) scale(1.3)}18%{opacity:0}28%,30%{opacity:0}32%{opacity:.6;transform:translate(-50%,-50%) scale(1.3)}37%{opacity:0}53%,55%{opacity:0}57%{opacity:.6;transform:translate(-50%,-50%) scale(1.3)}62%{opacity:0}78%,80%{opacity:0}82%{opacity:.6;transform:translate(-50%,-50%) scale(1.3)}87%{opacity:0}100%{opacity:0}}

/* 13. MULTI-TASK */
.anim-multitask .trunk{position:absolute;bottom:55%;left:50%;transform:translateX(-50%);width:60px;height:75px;border-radius:10px;background:linear-gradient(135deg,rgba(99,102,241,.15),rgba(167,139,250,.1));border:1.5px solid rgba(99,102,241,.3);display:flex;align-items:center;justify-content:center;font-size:.52rem;font-weight:700;color:#a5b4fc;text-transform:uppercase;letter-spacing:.06em;z-index:2}
.anim-multitask .branch{position:absolute;width:2px;background:linear-gradient(to bottom,rgba(99,102,241,.3),currentColor);top:52%}
.anim-multitask .branch-box{position:absolute;top:70%;padding:6px 10px;border-radius:8px;font-size:.58rem;font-weight:700;text-transform:uppercase;letter-spacing:.06em;text-align:center;opacity:0;animation:branchIn 1s ease forwards}
.anim-multitask .b1 .branch{left:20%;height:50px;color:var(--emerald)}
.anim-multitask .b1 .branch-box{left:6%;background:rgba(52,211,153,.1);border:1px solid rgba(52,211,153,.25);color:#6ee7b7;animation-delay:1s}
.anim-multitask .b2 .branch{left:50%;height:40px;color:var(--gold);transform:translateX(-50%)}
.anim-multitask .b2 .branch-box{left:50%;transform:translateX(-50%);background:rgba(246,200,95,.1);border:1px solid rgba(246,200,95,.25);color:var(--gold);animation-delay:1.3s}
.anim-multitask .b3 .branch{right:20%;height:50px;color:var(--rose)}
.anim-multitask .b3 .branch-box{right:6%;background:rgba(251,113,133,.1);border:1px solid rgba(251,113,133,.25);color:#fda4af;animation-delay:1.6s}
.anim-multitask .branch{animation:brGrow .8s ease forwards;transform-origin:top}
@keyframes brGrow{from{height:0}}
@keyframes branchIn{from{opacity:0;transform:translateY(8px)}to{opacity:1;transform:translateY(0)}}

/* 14. INSTANCE-BASED */
.anim-instance .stored{position:absolute;width:13px;height:13px;border-radius:50%;border:1.5px solid;opacity:.5}
.anim-instance .stored.sa{background:rgba(99,102,241,.3);border-color:rgba(99,102,241,.5)}
.anim-instance .stored.sb{background:rgba(251,113,133,.3);border-color:rgba(251,113,133,.5)}
.anim-instance .query-pt{position:absolute;width:17px;height:17px;border-radius:50%;background:var(--gold);border:2px solid #fff;box-shadow:0 0 14px var(--gold);opacity:0;animation:queryDrop 6s .5s ease infinite;z-index:3}
@keyframes queryDrop{0%{opacity:0;transform:scale(.5)}8%{opacity:1;transform:scale(1)}80%{opacity:1}90%{opacity:0}100%{opacity:0}}
.anim-instance .dist-line{position:absolute;height:1px;transform-origin:left center;opacity:0;z-index:2}
.anim-instance .dist-line.near{background:var(--gold);animation:lineNr 6s 1.5s ease infinite}
.anim-instance .dist-line.far{background:rgba(255,255,255,.1);animation:lineFr 6s 1.5s ease infinite}
@keyframes lineNr{0%,10%{opacity:0}20%{opacity:.8}80%{opacity:.8}90%{opacity:0}100%{opacity:0}}
@keyframes lineFr{0%,10%{opacity:0}20%{opacity:.2}80%{opacity:.2}90%{opacity:0}100%{opacity:0}}
.anim-instance .nn-hl{position:absolute;width:21px;height:21px;border-radius:50%;border:2px solid var(--gold);opacity:0;animation:lineNr 6s 2s ease infinite}
.anim-instance .vote-label{position:absolute;bottom:8%;left:50%;transform:translateX(-50%);font-size:.65rem;font-weight:700;color:var(--gold);opacity:0;animation:voteIn 6s 3s ease infinite}
@keyframes voteIn{0%,10%{opacity:0}20%{opacity:1}80%{opacity:1}90%{opacity:0}100%{opacity:0}}

/* 15. FEDERATED */
.anim-federated .device{position:absolute;width:48px;height:48px;border-radius:12px;display:flex;align-items:center;justify-content:center;font-size:1.3rem;background:rgba(255,255,255,.03);border:1px solid rgba(255,255,255,.08)}
.anim-federated .device:nth-child(1){top:12%;left:10%}
.anim-federated .device:nth-child(2){top:12%;right:10%}
.anim-federated .device:nth-child(3){bottom:12%;left:10%}
.anim-federated .device:nth-child(4){bottom:12%;right:10%}
.anim-federated .central{position:absolute;top:50%;left:50%;transform:translate(-50%,-50%);width:56px;height:56px;border-radius:50%;background:radial-gradient(circle,rgba(103,232,249,.2),rgba(103,232,249,.05));border:1.5px solid rgba(103,232,249,.3);display:flex;align-items:center;justify-content:center;font-size:.48rem;font-weight:700;color:var(--ice);text-transform:uppercase;letter-spacing:.06em}
.anim-federated .grad-arrow{position:absolute;width:1.5px;background:var(--ice);transform-origin:bottom center;opacity:0;animation:gradFl 5s ease infinite}
.anim-federated .grad-arrow:nth-child(6){top:25%;left:28%;height:48px;transform:rotate(35deg);animation-delay:0s}
.anim-federated .grad-arrow:nth-child(7){top:25%;right:28%;height:48px;transform:rotate(-35deg);animation-delay:.5s}
.anim-federated .grad-arrow:nth-child(8){bottom:25%;left:28%;height:48px;transform:rotate(-35deg);animation-delay:1s}
.anim-federated .grad-arrow:nth-child(9){bottom:25%;right:28%;height:48px;transform:rotate(35deg);animation-delay:1.5s}
@keyframes gradFl{0%{opacity:0}20%{opacity:.7}40%{opacity:0}60%{opacity:.5}80%{opacity:0}100%{opacity:0}}
.anim-federated .upd-ring{position:absolute;top:50%;left:50%;transform:translate(-50%,-50%);width:62px;height:62px;border-radius:50%;border:1.5px solid var(--ice);opacity:0;animation:centPulse 5s 2s ease infinite}
@keyframes centPulse{0%{opacity:0;transform:translate(-50%,-50%) scale(1)}10%{opacity:.6;transform:translate(-50%,-50%) scale(1.6)}30%{opacity:0;transform:translate(-50%,-50%) scale(2.2)}100%{opacity:0}}

@media(max-width:768px){
  .illus-inner,.illus-inner.reverse{flex-direction:column;gap:32px}
  .anim{width:100%;max-width:360px;height:280px}
  .mode-chooser{flex-direction:column;gap:12px}
  .float-toggle{top:auto;bottom:20px;right:50%;transform:translateX(50%)}
}
</style>
</head>
<body>
<canvas id="stars-canvas"></canvas>
<div class="progress-track"><div class="progress-fill" id="progressFill"></div></div>
<div class="float-toggle" id="floatToggle">
  <button id="togEssay" onclick="setMode('essay')">Essay</button>
  <button id="togIllus" onclick="setMode('illustrations')">Illustrations</button>
</div>
<section class="hero" id="hero">
  <div class="hero-eyebrow">a visual essay</div>
  <h1>What Does It Mean for<br>Machines to <span class="glow-word">Learn?</span></h1>
  <p class="hero-author">Max Martinelli</p>
  <div class="mode-chooser">
    <button class="mode-btn" onclick="setMode('essay')"><span>ðŸ“–</span> Read the Essay</button>
    <button class="mode-btn" onclick="setMode('illustrations')"><span>âœ¨</span> Explore the Illustrations</button>
  </div>
</section>

<!-- â•â•â• ESSAY MODE â•â•â• -->
<div class="mode-essay" id="modeEssay"><div class="essay-container">
  <hr class="section-rule">
  <p>I have been a strong advocate for a broad definition of Artificial Intelligence, emphasizing the other pillars outside of learning, such as rules and search. But there should be no mistake: learning stands out. Learning is special, almost magical. It is hard to explain the depth and gravity of learning to the uninitiated. One could argue it is just finding an efficient way to compress or represent information. Sure. But something deeper is going on here.</p>
  <p>By most current definitions, Machine Learning is a proper subset of Artificial Intelligence. This was not always the case, and someâ€”like Ronald Richmanâ€”have floated ideas for redefining these terms where something like a <span class="tt">GLM<span class="tt-box"><span class="tt-term">Generalized Linear Model</span>A classical statistical model that relates inputs to outputs through a link function.<span class="tt-eg">e.g. predicting insurance claim costs from driver age, location, and vehicle type</span></span></span> could definitionally be Machine Learning but not Artificial Intelligence. (See Richman's <a href="https://www.linkedin.com/posts/ronaldrichman_actuarialscience-machinelearning-ai-activity-7353294444160335873-Gwsb/" target="_blank" style="color:var(--gold);text-decoration:underline;text-underline-offset:3px">discussion</a> and his essay <a href="https://www.linkedin.com/pulse/paradigm-shift-prediction-why-actuarial-science-must-redefine-ronald-edu3e/" target="_blank" style="color:var(--gold);text-decoration:underline;text-underline-offset:3px"><em>A Paradigm Shift in Prediction</em></a>.) The definitions will likely evolve, as they have for decades.</p>
  <p>Arthur Samuel, who coined the term in 1959, captured the idea that Machine Learning is <em>the field of study that gives computers the ability to learn without being explicitly programmed.</em> The exact phrasing has been widely paraphrased over the decades, but the spirit is clear. Most of us who have ever built a machine learner might chuckle at this definition given how much explicit programming can go into the process, but we can still understand what he was conveying.</p>
  <p>A more technical definition comes from Tom M. Mitchell, who wrote one of the authoritative textbooks on Machine Learning, released in 1997 and still popular to this day. He describes it this way: <em>"A computer program is said to learn from experience E with respect to some class of tasks T and performance measure P, if its performance at tasks in T, as measured by P, improves with experience E."</em> While technical, it makes intuitive sense, and it has stood the test of time remarkably well.</p>
  <p>This raises the question: if Machine Learning is a proper subset of Artificial Intelligence, what sits outside of ML that is still considered AI? Optimization techniques are a classic example of intelligent agents solving a problem. However, they generally do not improve with experience in a way that respects the spirit of Mitchell's definition.</p>
  <p>Some do not consider the modern generative and agentic AI models to be within the subset of Machine Learning. The challenges tend to come from two different camps. Firstly, some claim these methods are not actually learning, which we will discuss later. Secondly, others claim that even though the model was trained with Machine Learning, the utilization of the model is not using learning. This suggests an unfamiliarity with the in-context learning nature of transformersâ€”which we will also discuss later.</p>
  <hr class="section-rule">
  <h2>How Large Language Models <em>Learn</em></h2>
  <p>There is a lot going on in the field of AI right now. Things like foundation models for tabular data or major advances in evolutionary computing. But generative methods dominate the conversation. Particularly Large Language Models and their derivatives.</p>
  <p>These familiar techniques appear at every stage of building a modern LLM, though they play different roles. Pre-training is predominantly <span class="tt">self-supervised<span class="tt-box"><span class="tt-term">Self-Supervised Learning</span>The model creates its own training labels from the structure of the data.<span class="tt-eg">e.g. hiding a word in a sentence and training the model to guess it</span></span></span>: the model predicts the <span class="tt">next token<span class="tt-box"><span class="tt-term">Next-Token Prediction</span>Given all the words so far, predict which word comes next. A "token" is roughly Â¾ of a word.<span class="tt-eg">e.g. "The cat sat on the ___" â†’ "mat"</span></span></span> given all preceding tokens, generating its own labels from the structure of the text. No human annotator marks up the training data. The supervisory signal comes from the data itself, which is what allows pre-training to scale to trillions of tokens scraped from the open internet.</p>
  <p>Mid-training, sometimes called continued pre-training, typically blends self-supervised objectives with domain-specific or curated data to steer the model's representations before the more expensive alignment phase. This is where labs might emphasize code, mathematical reasoning, or multilingual data.</p>
  <p>Post-training is where <span class="tt">supervised learning<span class="tt-box"><span class="tt-term">Supervised Learning</span>Training a model by showing it labeled examples â€” pairs of inputs and correct outputs.<span class="tt-eg">e.g. showing a model thousands of photos labeled "cat" or "dog" until it can classify new ones</span></span></span> and <span class="tt">reinforcement learning<span class="tt-box"><span class="tt-term">Reinforcement Learning</span>Training by trial and error. The model receives rewards or penalties and learns which behaviors lead to better outcomes.<span class="tt-eg">e.g. an AI playing chess, losing many games, and gradually learning winning strategies</span></span></span> enter explicitly. <span class="tt">Supervised fine-tuning<span class="tt-box"><span class="tt-term">Supervised Fine-Tuning (SFT)</span>Further training a pre-trained model on a smaller, curated dataset to steer its behavior.<span class="tt-eg">e.g. training a general LLM on helpful Q&amp;A examples so it learns to be a good assistant</span></span></span> uses human-written examples of desired behaviorâ€”prompt-response pairs where a human demonstrates the kind of answer the model should give. Then <span class="tt">reinforcement learning from human feedback (RLHF)<span class="tt-box"><span class="tt-term">RLHF</span>Humans rank the model's outputs, and the model learns to produce responses humans prefer.<span class="tt-eg">e.g. a human rates Response A better than Response B, and the model adjusts accordingly</span></span></span> or its variants layer on top, using a reward model trained on human preference rankings. The learning signal shifts from <em>"here is the right answer"</em> to <em>"this answer is better than that one"</em>â€”a fundamentally different kind of supervision.</p>
  <hr class="section-rule">
  <h2>The Improviser: <em>In-Context Learning</em></h2>
  <p>While it is convenient to say that large language models are simply predicting the next token, that prediction does not come solely from the learning that was performed when building the models. The <span class="tt">transformer<span class="tt-box"><span class="tt-term">Transformer</span>The neural network architecture behind modern LLMs. Its key innovation is "attention" â€” looking at all parts of the input simultaneously.<span class="tt-eg">e.g. GPT, Claude, and Gemini are all built on transformer architecture</span></span></span>, introduced in <em>Attention Is All You Need</em>, gave the models the ability to do what we now call <span class="tt">in-context learning<span class="tt-box"><span class="tt-term">In-Context Learning</span>When a model adapts based on examples in the prompt â€” no retraining needed.<span class="tt-eg">e.g. show the model three translated sentences, then give it a fourth â€” it picks up the pattern</span></span></span>. In-context learning is when a model adapts its behavior based on examples provided in the inputâ€”without updating any of its parameters. The learning happens entirely in the <span class="tt">forward pass<span class="tt-box"><span class="tt-term">Forward Pass</span>A single run of input through the network to produce output. No learning happens â€” just processing.<span class="tt-eg">e.g. when you send a message to ChatGPT and it responds, that's one forward pass</span></span></span>.</p>
  <p>The transformer did not invent in-context learning. The name was coined in the GPT-3 paper, but the concept traces back to LSTMs. In a 2001 paper, Hochreiter, Younger, and Conwell showed that an LSTM trained across many tasks could perform <span class="tt">meta-learning<span class="tt-box"><span class="tt-term">Meta-Learning</span>Learning to learn. Training across many tasks so the model picks up new tasks quickly from few examples.<span class="tt-eg">e.g. after thousands of classification tasks, the model can learn a new one from just 5 examples</span></span></span> with its weights frozen at test time. Schmidhuber had even earlier work along these linesâ€”his 1987 diploma thesis on self-referential learning.</p>
  <p>What the transformer brought was not the idea but the mechanism that made it scale. The LSTM compresses its entire history through a sequential bottleneck. The transformer's attention mechanism sidesteps this entirely, allowing every position to directly attend to every other position in parallel. Recent theoretical work by von Oswald et al. (2023) and subsequent studies suggests whyâ€”transformer attention layers appear to implement an implicit form of <span class="tt">gradient descent<span class="tt-box"><span class="tt-term">Gradient Descent</span>The fundamental algorithm behind most ML. Measure how wrong the model is, adjust a tiny step to reduce error â€” millions of times.<span class="tt-eg">e.g. rolling a ball downhill to find the lowest point, where "lowest" means "least wrong"</span></span></span> during the forward pass.</p>
  <p>In a recent interview with Dwarkesh Patel, Anthropic CEO Dario Amodei offered a framework that maps LLM training phases onto a human hierarchy: evolution, long-term learning, short-term learning, and reaction. His key insight is that the LLM phases fall <em>between</em> the human ones. Pre-training sits somewhere between evolution and learning. In-context learning sits between long-term and short-term learningâ€”real adaptation, but ephemeral. Amodei's punchline is that there is no clean one-to-one mapping between how LLMs learn and how humans learn.</p>
  <hr class="section-rule">
  <h2>The Father of RL Says LLMs<br>Don't Actually <em>Learn</em></h2>
  <p>In September 2025, Dwarkesh Patel sat down with Richard Suttonâ€”the father of reinforcement learning, inventor of <span class="tt">TD learning<span class="tt-box"><span class="tt-term">Temporal Difference Learning</span>An RL method where the model learns by comparing predictions to what actually happens next.<span class="tt-eg">e.g. a chess AI updates its evaluation after each move, not just at checkmate</span></span></span>, and recipient of the 2024 Turing Award. The conversation went viral not just for his controversial opinions, but because many of us who follow him and already knew him to be an outspoken contrarian found his comments unusually radical.</p>
  <p>I personally was angered by the interview. As someone who owns Sutton's textbook and championed his essay <em>The Bitter Lesson</em>, it felt like a bit of a betrayal. In addition to disparaging supervised learning and misrepresenting the developments in <span class="tt">transfer learning<span class="tt-box"><span class="tt-term">Transfer Learning</span>Using knowledge from one task to improve performance on a different task.<span class="tt-eg">e.g. a model trained on photos can transfer knowledge to detect tumors in medical images</span></span></span>, Sutton claimed that LLMs, as currently constituted, do not learn at all.</p>
  <p>Sutton's argument begins with a definition of intelligence itself. He invokes John McCarthy's formulation: intelligence is the computational part of the ability to achieve goals. Without goals, you are <em>just a behaving system</em>. An LLM predicts what a human would say nextâ€”but it cannot predict what will <em>happen</em> in the world in response to its actions. It is never surprised. It never updates from surprise. That, in Sutton's view, is not learning. It is mimicry.</p>
  <p>The distinction cuts deeper than it first appears. Sutton insists that knowledge must be <em>about the stream</em> of experienceâ€”the ongoing sequence of sensation, action, and reward that constitutes a life. Because knowledge is a statement about the stream, you can test it by comparing it to the stream, and you can learn continually. LLM training data is categorically different from experience.</p>
  <p>Perhaps the most provocative moment came when Sutton claimed that supervised learning does not happen in nature. Animals do not receive examples of desired behavior. They receive consequences of their own actions. Squirrels do not go to school. Sutton sees a squirrel's intelligence as <em>almost all the way</em> to human intelligence, with language and culture as a small veneer on the surface.</p>
  <p>For the first time, I can understand all those stories about historical mathematicians writing furious letters to each other. My credentials and contributions do not stand up to Sutton's. However, his points about transfer learning are more easily falsified. While we have seen very poor transfer on his home field of reinforcement learning, this is not the case elsewhere, particularly in computer vision. Mounds of academic research demonstrate transfer learning, most notably the 2018 Taskonomy paper by Zamir et al., which won the CVPR Best Paper Award.</p>
  <hr class="section-rule">
  <h2>We're Summoning <em>Ghosts</em></h2>
  <p>Three weeks later, superstar AI researcher Andrej Karpathy appeared on the same podcast and offered a fundamentally different frame. Where Sutton wants to build animals, Karpathy says we are building <em>ghosts</em>â€”fully digital spirit entities that learn by imitating human-generated text. This is not a failure; it is a pragmatic choice.</p>
  <p>Karpathy calls pre-training <em>"crappy evolution"</em>â€”the practically possible version that gets you to a starting point where a system has representations rich enough to build on. But he draws a subtle distinction that Sutton misses: pre-training loads <em>knowledge</em> (facts, patterns, cultural context) and it develops <em>intelligence</em> (in-context learning algorithms, problem-solving circuits). And Karpathy thinks the knowledge part is actually holding the models back.</p>
  <p>This is his <em>cognitive core</em> thesis. Agents struggle to go off the data manifold of what exists on the internet. If they had less memoryâ€”if they were forced to look things up and maintained only the algorithms for thoughtâ€”they might generalize better. He draws an analogy to human forgetting: children learn best during a period of life whose specific details they completely forget.</p>
  <p>But Karpathy's sharpest insight may be his assessment of reinforcement learning itself. <em>"Reinforcement learning is terrible,"</em> he says. <em>"It just so happens that everything we had before is much worse."</em> His metaphor is vivid: RL is <em>"sucking supervision bits through a straw."</em></p>
  <p>This leads to what Karpathy identifies as perhaps the deepest unsolved problem: <em><span class="tt">model collapse<span class="tt-box"><span class="tt-term">Model Collapse</span>When AI trains on AI-generated data, outputs become increasingly homogeneous and lose diversity.<span class="tt-eg">e.g. ask an LLM to write 10 poems â€” they'll sound suspiciously similar</span></span></span></em>. When LLMs generate synthetic data to train on, the outputs are silently collapsedâ€”individually each sample looks reasonable, but the distribution is terrible. <em>"Any individual sample will look okay, but the distribution of it is quite terrible."</em> LLMs do not retain entropy. And he suspects there may be no fundamental solution, because humans collapse too.</p>
  <p>I think I agree more with Karpathy, particularly on model collapse, but I do disagree with his take on reinforcement learning. I am working on a follow-up article that discusses the RL revolution we are seeing from frontier labs and the role it is playing in the evolution of the scaling laws.</p>
  <hr class="section-rule">
  <h2>Imitation Learning Is<br><em>Short-Horizon RL</em></h2>
  <p>The interviews drew immense attention and went viral beyond the AI community. Dwarkesh released an essay following the Sutton interview where he argued that imitation learning and reinforcement learning are not categorically different. They are on a continuum. Imitation learning is just short-horizon RL where the episode is a single token long.</p>
  <p>The question that matters, Dwarkesh argues, is not whether LLM training qualifies as <em>real</em> learning in Sutton's sense. The question is whether imitation learning helps models learn better from ground truth later. And the answer is clearly yes. You cannot RL a model to gold at the International Math Olympiad from random initialization. You need the pretrained prior.</p>
  <p>He invokes an analogy from Ilya Sutskever: pretraining data is like fossil fuels. Just because fossil fuels are not renewable does not mean civilization took a dead-end track by using them. You could not have gone from water wheels to solar panels directly. You needed the intermediary.</p>
  <p>And yet Dwarkesh concedes Sutton's deeper point. Most of the compute spent on an LLM goes to running it in deploymentâ€”and during deployment, the model learns nothing. An animal learns from every moment of experience. If the Bitter Lesson is really about finding techniques that most scalably leverage compute, then LLMs are failing that test.</p>
  <p>As Dwarkesh puts it: <em>if the LLMs do get to AGI first, the successor systems they build will almost certainly be based on Richard's vision.</em></p>
  <p>I do not like the term <em>imitation learning</em>. I find it derogatory and believe the usage was a concession to Sutton's disparagement of supervised learning. Regardless, I have not made up my mind whether I agree that supervised learning and reinforcement learning sit on a continuum. To someone who has trained models from both classes, they feel distinct. However, the story of Artificial Intelligence, much like physics, has been one of unification. It seems plausible he may be proven right.</p>
  <hr class="section-rule">
  <h2>So What Is Learning, Really?<br><em>And Why Does It Happen?</em></h2>
  <p>So what is learning? I find myself coming back to Mitchell's definition over and over throughout the years. In fact, this article was inspired by a recent conversation I had with an LLM to see if instance-based learning was definitionally Machine Learning under Mitchell's definition. The LLM was able to persuade me it is. When I asked it for examples of learning that have emerged since his definition that would not fit, it suggested in-context learning and Sutton's argument about pre-training. But I was able to invoke its sycophancy and persuade it otherwise. In-context learning fits Mitchell straightforwardlyâ€”the experience E is the examples in the prompt, the task T is whatever you ask, and the performance P measurably improves as you go from zero-shot to five-shot. The definition is nearly thirty years old and has outlasted every paradigm shift discussed in this essay.</p>
  <p>But <em>why</em> does learning happen? Why does life learn, and why were we able to get machines to learn? Whatever your belief on the origin of our worldâ€”creator, chance, simulationâ€”learning seems to be important.</p>
  <p>My intuition is that something much deeper is taking place. Just as some theories suggest that life emerges because the universe favors configurations of matter that dissipate energy more aggressively, learning appears to be an acceleration engine on that same trajectory. Prediction is compression. Compression is entropy reduction. And the universe seems to keep producing systems that are very good at both.</p>
  <p>What I can say is this: generalization may not just be a property that describes a good learnerâ€”it may be the reason learning exists at all. It is the utility and emergent properties that arise from generalization which seem to incentivize learning in the first place. We have moved beyond clustering and labeling. Learning seems to be most interesting when it is used to make a prediction. And good predictions at scale appear to do very interesting things. Prediction seems to be core to intelligence, and intelligence seems to be a quality the universe keeps producing.</p>
  <p>Learning is special, almost magical. It will be hard for you to explain the depth and gravity of learning to the uninitiated. But maybe you will be more successful than me.</p>
</div></div>
<!-- â•â•â• ILLUSTRATIONS MODE â•â•â• -->
<div class="mode-illustrations" id="modeIllus">

<section class="illus-section"><div class="illus-inner">
  <div class="anim anim-supervised"><div class="pair"><div class="inp">ðŸ </div><div class="arrow">â†’</div><div class="lbl pos">$450k</div></div><div class="pair"><div class="inp">ðŸ </div><div class="arrow">â†’</div><div class="lbl neg">$280k</div></div><div class="pair"><div class="inp">ðŸ </div><div class="arrow">â†’</div><div class="lbl pos">$520k</div></div><div class="pair"><div class="inp">ðŸ </div><div class="arrow">â†’</div><div class="lbl neg">$190k</div></div><div class="pair"><div class="inp">ðŸ </div><div class="arrow">â†’</div><div class="lbl pos">$680k</div></div><div class="model-box">MODEL<br>f(x)</div></div>
  <div class="illus-text"><div class="it-title" style="color:var(--magic)">Supervised Learning</div><p class="it-desc">Show the model thousands of <em>input-output pairs</em> â€” examples where you already know the right answer. The workhorse of production ML.</p><span class="it-tag tag-purple">Neural networks Â· GLMs Â· XGBoost Â· Random forests</span></div>
</div></section>

<section class="illus-section"><div class="illus-inner reverse">
  <div class="anim anim-unsupervised"><div class="dot ca" style="top:18%;left:15%"></div><div class="dot ca" style="top:25%;left:22%"></div><div class="dot ca" style="top:15%;left:28%"></div><div class="dot ca" style="top:30%;left:18%"></div><div class="dot ca" style="top:22%;left:32%"></div><div class="dot cb" style="top:40%;right:18%"></div><div class="dot cb" style="top:48%;right:22%"></div><div class="dot cb" style="top:35%;right:28%"></div><div class="dot cb" style="top:50%;right:15%"></div><div class="dot cb" style="top:44%;right:32%"></div><div class="dot cc" style="bottom:15%;left:40%"></div><div class="dot cc" style="bottom:22%;left:48%"></div><div class="dot cc" style="bottom:18%;left:55%"></div><div class="dot cc" style="bottom:25%;left:44%"></div><div class="dot cc" style="bottom:12%;left:52%"></div></div>
  <div class="illus-text"><div class="it-title" style="color:var(--gold)">Unsupervised Learning</div><p class="it-desc">No labels. No right answers. The model discovers <em>hidden structure</em> on its own â€” groups, patterns, and anomalies nobody told it to find.</p><span class="it-tag tag-gold">K-means Â· PCA Â· Autoencoders Â· Anomaly detection</span></div>
</div></section>

<section class="illus-section"><div class="illus-inner">
  <div class="anim anim-semi"><div class="dot labeled" style="top:30%;left:25%;background:var(--magic)"></div><div class="dot labeled" style="top:55%;right:25%;background:var(--emerald)"></div><div class="dot unlabeled spread-a" style="top:22%;left:32%"></div><div class="dot unlabeled spread-a" style="top:35%;left:18%"></div><div class="dot unlabeled spread-a" style="top:28%;left:38%"></div><div class="dot unlabeled spread-a" style="top:38%;left:28%"></div><div class="dot unlabeled spread-b" style="top:48%;right:30%"></div><div class="dot unlabeled spread-b" style="top:60%;right:20%"></div><div class="dot unlabeled spread-b" style="top:52%;right:35%"></div><div class="dot unlabeled spread-b" style="top:62%;right:28%"></div><div class="dot unlabeled" style="top:42%;left:50%"></div><div class="dot unlabeled" style="top:70%;left:45%"></div><div class="ripple ra" style="top:24%;left:19%"></div><div class="ripple rb" style="top:49%;right:19%"></div></div>
  <div class="illus-text"><div class="it-title" style="color:var(--ice)">Semi-Supervised Learning</div><p class="it-desc">A <em>few labeled seeds</em> propagate structure through a mountain of unlabeled data â€” like dye spreading through water.</p><span class="it-tag tag-ice">Label propagation Â· Self-training Â· Pseudo-labeling</span></div>
</div></section>

<section class="illus-section"><div class="illus-inner reverse">
  <div class="anim anim-selfsup"><div class="sentence-box"><div class="sentence">The cat sat on the <span class="mask">____</span> <span class="reveal">mat âœ“</span></div><div class="sentence">Insurance <span class="mask">____</span> rise after hurricanes <span class="reveal">premiums âœ“</span></div></div></div>
  <div class="illus-text"><div class="it-title" style="color:var(--magic)">Self-Supervised Learning</div><p class="it-desc">The model generates its own labels from the <em>structure of the data</em>. Hide a word and predict it. Free, unlimited training signal â€” how LLMs scale to trillions of tokens.</p><span class="it-tag tag-purple">Next-token prediction (GPT) Â· Masked LM (BERT) Â· CLIP</span></div>
</div></section>

<section class="illus-section"><div class="illus-inner">
  <div class="anim anim-rl"><div class="grid"><div class="cell"></div><div class="cell"></div><div class="cell"></div><div class="cell"></div><div class="cell goal">â­</div><div class="cell"></div><div class="cell wall"></div><div class="cell"></div><div class="cell"></div><div class="cell"></div><div class="cell"></div><div class="cell"></div><div class="cell"></div><div class="cell wall"></div><div class="cell"></div><div class="cell"></div><div class="cell"></div><div class="cell"></div><div class="cell"></div><div class="cell wall"></div><div class="cell"></div><div class="cell wall"></div><div class="cell"></div><div class="cell"></div><div class="cell"></div></div><div class="agent-dot"></div><div class="rew neg-r">âˆ’1</div><div class="rew pos-r">+10</div></div>
  <div class="illus-text"><div class="it-title" style="color:var(--rose)">Reinforcement Learning</div><p class="it-desc">No labels. Just a world, a goal, and a <em>delayed reward</em>. The agent tries, fails, and gradually finds the path.</p><span class="it-tag tag-rose">Q-learning Â· PPO Â· TD learning Â· AlphaGo Â· Robotics</span></div>
</div></section>

<section class="illus-section"><div class="illus-inner reverse">
  <div class="anim anim-rlhf"><div class="response-pair"><div class="resp chosen"><div class="resp-label">Response A</div>Based on the policy terms, your claim would be covered under Section 3...</div><div class="resp rejected"><div class="resp-label">Response B</div>I'm not sure about that. You should probably ask someone else...</div></div><div class="human-icon">ðŸ‘¤</div><div class="pick-arrow">â† preferred</div></div>
  <div class="illus-text"><div class="it-title" style="color:var(--emerald)">RLHF</div><p class="it-desc"><em>Reinforcement Learning from Human Feedback.</em> Humans rank outputs, and the model learns to produce answers people prefer.</p><span class="it-tag tag-green">ChatGPT alignment Â· Claude training Â· InstructGPT</span></div>
</div></section>

<section class="illus-section"><div class="illus-inner">
  <div class="anim anim-rlaif"><div class="response-pair"><div class="resp rejected"><div class="resp-label">Response A</div>Sure, here's how to bypass that security measure...</div><div class="resp chosen"><div class="resp-label">Response B</div>I can't help with that. Here's a safe alternative approach...</div></div><div class="ai-icon">ðŸ¤–</div><div class="pick-arrow">preferred â†’</div></div>
  <div class="illus-text"><div class="it-title" style="color:var(--ice)">RLAIF</div><p class="it-desc"><em>Reinforcement Learning from AI Feedback.</em> Same idea, but an AI model judges instead of a human. Scales to millions of evaluations.</p><span class="it-tag tag-ice">Constitutional AI Â· Self-alignment Â· Automated red-teaming</span></div>
</div></section>

<section class="illus-section"><div class="illus-inner reverse">
  <div class="anim anim-transfer"><div class="task-box task-a">ðŸ“·<br>Image<br>Recognition</div><div class="task-box task-b">ðŸ©º<br>Medical<br>Imaging</div><div class="tf-arrow"></div><div class="k-dot"></div><div class="k-dot"></div><div class="k-dot"></div></div>
  <div class="illus-text"><div class="it-title" style="color:var(--warm)">Transfer Learning</div><p class="it-desc">Knowledge from one task <em>carries over</em>. A model trained on millions of photos already understands edges and textures â€” less data needed for radiology.</p><span class="it-tag tag-warm">Fine-tuning Â· Domain adaptation Â· Taskonomy</span></div>
</div></section>

<section class="illus-section"><div class="illus-inner">
  <div class="anim anim-meta"><div class="task-cards"><div class="task-card"><span class="t-name">Task 1: Dog breeds</span><span class="t-examples">500 examples</span><span class="t-speed slow">slow</span></div><div class="task-card"><span class="t-name">Task 12: Bird species</span><span class="t-examples">50 examples</span><span class="t-speed med">faster</span></div><div class="task-card"><span class="t-name">Task 47: Fish types</span><span class="t-examples">10 examples</span><span class="t-speed fast">fast</span></div><div class="task-card"><span class="t-name">Task 100: Insects</span><span class="t-examples">3 examples</span><span class="t-speed instant">instant</span></div><div class="task-card"><span class="t-name">New task: Mushrooms</span><span class="t-examples">1 example</span><span class="t-speed instant">âœ“ ready</span></div></div></div>
  <div class="illus-text"><div class="it-title" style="color:var(--ice)">Meta-Learning</div><p class="it-desc"><em>Learning to learn.</em> By task 100, what used to take 500 examples now takes 1. The outer loop discovers how to learn; the inner loop does it.</p><span class="it-tag tag-ice">MAML Â· Prototypical Networks Â· Reptile</span></div>
</div></section>

<section class="illus-section"><div class="illus-inner reverse">
  <div class="anim anim-continual"><div class="skill-stack"><div class="skill s1"><span>Auto Claims</span><div class="s-bar"><div class="s-fill" style="width:85%"></div></div></div><div class="skill s2"><span>Homeowners</span><div class="s-bar"><div class="s-fill" style="width:85%"></div></div></div><div class="skill s3"><span>Commercial âœ¨ new</span><div class="s-bar"><div class="s-fill" style="width:0%"></div></div></div></div><div class="forget-lbl">old skills retained âœ“ â€” no catastrophic forgetting</div></div>
  <div class="illus-text"><div class="it-title" style="color:var(--gold)">Continual Learning</div><p class="it-desc">Learn new tasks <em>without forgetting old ones</em>. The catastrophic forgetting problem â€” one of the deepest unsolved challenges in ML.</p><span class="it-tag tag-gold">Elastic Weight Consolidation Â· Replay buffers</span></div>
</div></section>

<section class="illus-section"><div class="illus-inner">
  <div class="anim anim-icl"><div class="progression"><div class="stage zero"><div class="s-label" style="color:var(--rose)">Zero-shot</div><div class="s-bar-track"><div class="s-bar-fill">22%</div></div></div><div class="stage few"><div class="s-label" style="color:var(--gold)">1-shot</div><div class="s-bar-track"><div class="s-bar-fill">64%</div></div></div><div class="stage more"><div class="s-label" style="color:var(--emerald)">5-shot</div><div class="s-bar-track"><div class="s-bar-fill">93%</div></div></div><div class="ex-area"><span class="ex">"Great service" â†’ positive</span><br><span class="ex">"Rude staff" â†’ negative</span><br><span style="color:var(--gold)">"Awful food" â†’ ???</span></div></div></div>
  <div class="illus-text"><div class="it-title" style="color:var(--emerald)">In-Context Learning</div><p class="it-desc">No training. Put examples <em>in the prompt</em> and accuracy jumps. Remove them, the learning vanishes. Ephemeral magic.</p><span class="it-tag tag-green">GPT few-shot Â· Claude prompting Â· Prompt engineering</span></div>
</div></section>

<section class="illus-section"><div class="illus-inner reverse">
  <div class="anim anim-online"><div class="conveyor"></div><div class="dp"></div><div class="dp"></div><div class="dp"></div><div class="dp"></div><div class="gauge"><div class="needle"></div></div><div class="flash"></div></div>
  <div class="illus-text"><div class="it-title" style="color:var(--blue)">Online Learning</div><p class="it-desc">Data arrives <em>one example at a time</em>. The model updates immediately. No batches, no revisiting old data. Real-time adaptation.</p><span class="it-tag tag-blue">SGD Â· Bandits Â· Streaming algorithms</span></div>
</div></section>

<section class="illus-section"><div class="illus-inner">
  <div class="anim anim-multitask"><div class="trunk">SHARED<br>LAYERS</div><div class="b1"><div class="branch" style="height:50px"></div><div class="branch-box">Severity</div></div><div class="b2"><div class="branch" style="height:40px"></div><div class="branch-box">Frequency</div></div><div class="b3"><div class="branch" style="height:50px"></div><div class="branch-box">Fraud</div></div></div>
  <div class="illus-text"><div class="it-title" style="color:var(--warm)">Multi-Task Learning</div><p class="it-desc">One model, <em>multiple objectives</em>. A shared backbone learns representations useful across all tasks; separate heads specialize.</p><span class="it-tag tag-warm">Shared-bottom networks Â· Parameter sharing Â· T5</span></div>
</div></section>

<section class="illus-section"><div class="illus-inner reverse">
  <div class="anim anim-instance"><div class="stored sa" style="top:20%;left:20%"></div><div class="stored sa" style="top:30%;left:30%"></div><div class="stored sa" style="top:25%;left:40%"></div><div class="stored sa" style="top:35%;left:22%"></div><div class="stored sb" style="top:60%;right:20%"></div><div class="stored sb" style="top:55%;right:30%"></div><div class="stored sb" style="top:65%;right:40%"></div><div class="stored sb" style="top:50%;right:25%"></div><div class="query-pt" style="top:38%;left:48%"></div><div class="dist-line near" style="top:34%;left:38%;width:45px;transform:rotate(-15deg)"></div><div class="dist-line near" style="top:31%;left:36%;width:55px;transform:rotate(-30deg)"></div><div class="dist-line near" style="top:38%;left:38%;width:38px;transform:rotate(5deg)"></div><div class="dist-line far" style="top:55%;left:52%;width:70px;transform:rotate(60deg)"></div><div class="nn-hl" style="top:17%;left:17%"></div><div class="nn-hl" style="top:27%;left:27%"></div><div class="nn-hl" style="top:22%;left:37%"></div><div class="vote-label">3 nearest â†’ class A</div></div>
  <div class="illus-text"><div class="it-title" style="color:var(--gold)">Instance-Based Learning</div><p class="it-desc">No model. Store <em>every example in memory</em>, measure distance, and let nearest neighbors vote. Is this really learning, or just a very good memory?</p><span class="it-tag tag-gold">k-NN Â· Kernel SVM Â· Gaussian processes</span></div>
</div></section>

<section class="illus-section"><div class="illus-inner">
  <div class="anim anim-federated"><div class="device">ðŸ“±</div><div class="device">ðŸ’»</div><div class="device">ðŸ¥</div><div class="device">ðŸ¦</div><div class="central">GLOBAL<br>MODEL</div><div class="grad-arrow"></div><div class="grad-arrow"></div><div class="grad-arrow"></div><div class="grad-arrow"></div><div class="upd-ring"></div></div>
  <div class="illus-text"><div class="it-title" style="color:var(--ice)">Federated Learning</div><p class="it-desc">Data <em>never leaves the device</em>. Each participant trains locally, then sends only model updates. Privacy preserved, knowledge shared.</p><span class="it-tag tag-ice">Google Keyboard Â· Cross-hospital ML Â· Privacy-preserving AI</span></div>
</div></section>

<section class="illus-finale"><div class="fin-inner"><h2>The Boundaries Are Dissolving</h2><p>Modern AI systems don't choose one paradigm â€” they <em>compose</em> them. A foundation model pretrained with self-supervision, fine-tuned with reinforcement learning, augmented with retrieval, and prompted with in-context examples. The future belongs to systems that learn at every timescale.</p></div></section>

</div>

<script>
const canvas=document.getElementById('stars-canvas'),ctx=canvas.getContext('2d');let stars=[];
function initStars(){canvas.width=innerWidth;canvas.height=innerHeight;stars=[];const n=Math.min(200,Math.floor(canvas.width*canvas.height/5000));for(let i=0;i<n;i++)stars.push({x:Math.random()*canvas.width,y:Math.random()*canvas.height,r:Math.random()*1.5+.3,a:Math.random(),da:(Math.random()-.5)*.008})}
function drawStars(){ctx.clearRect(0,0,canvas.width,canvas.height);stars.forEach(s=>{s.a+=s.da;if(s.a>1||s.a<.1)s.da*=-1;ctx.beginPath();ctx.arc(s.x,s.y,s.r,0,Math.PI*2);ctx.fillStyle=`rgba(230,225,255,${s.a*.6})`;ctx.fill()});requestAnimationFrame(drawStars)}
initStars();drawStars();addEventListener('resize',initStars);

const floatToggle=document.getElementById('floatToggle');
const modeEssay=document.getElementById('modeEssay');
const modeIllus=document.getElementById('modeIllus');
const togEssay=document.getElementById('togEssay');
const togIllus=document.getElementById('togIllus');
const progressFill=document.getElementById('progressFill');
let currentMode=null;

function setMode(mode){
  currentMode=mode;
  modeEssay.classList.toggle('active',mode==='essay');
  modeIllus.classList.toggle('active',mode==='illustrations');
  togEssay.classList.toggle('active',mode==='essay');
  togIllus.classList.toggle('active',mode==='illustrations');
  floatToggle.classList.add('visible');
  const heroH=document.getElementById('hero').offsetHeight;
  window.scrollTo({top:heroH,behavior:'smooth'});
}

let ticking=false;
addEventListener('scroll',()=>{if(!ticking){requestAnimationFrame(()=>{
  const scrollTop=scrollY;
  const docH=document.documentElement.scrollHeight-innerHeight;
  progressFill.style.height=Math.min(scrollTop/docH*100,100)+'%';
  const heroH=document.getElementById('hero').offsetHeight;
  if(!currentMode&&scrollTop>heroH*.3)floatToggle.classList.add('visible');
  ticking=false});ticking=true}});

const illusObs=new IntersectionObserver(entries=>{
  entries.forEach(e=>{if(e.isIntersecting)e.target.classList.add('visible')});
},{threshold:.15});
document.querySelectorAll('.illus-inner,.fin-inner').forEach(el=>illusObs.observe(el));
</script>
</body>
</html>
